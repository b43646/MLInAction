{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a7caaf-c192-4fac-bf81-33efdf0ba3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a7b937-f454-4b7f-9f44-09bf27e5e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc_0): Linear(in_features=100, out_features=10, bias=False)\n",
      "  (fc_1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (fc_2): Linear(in_features=5, out_features=1, bias=False)\n",
      ")\n",
      "tensor([-0.0182], grad_fn=<SqueezeBackward4>)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 10]           1,000\n",
      "            Linear-2                    [-1, 5]              50\n",
      "            Linear-3                    [-1, 1]               5\n",
      "================================================================\n",
      "Total params: 1,055\n",
      "Trainable params: 1,055\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_0 = nn.Linear(100, 10, bias=False)\n",
    "        self.fc_1 = nn.Linear(10, 5, bias=False)\n",
    "        self.fc_2 = nn.Linear(5, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_0(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(model)\n",
    "input = torch.rand(100)\n",
    "output = model(input)\n",
    "print(output)\n",
    "\n",
    "summary(model, (100,), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f8ba76a-e3eb-4708-92a7-6d802d4b3df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2120, 0.1772, 0.1916, 0.2044, 0.2148],\n",
      "        [0.1932, 0.2119, 0.2076, 0.1717, 0.2156],\n",
      "        [0.2025, 0.1852, 0.1964, 0.2022, 0.2136],\n",
      "        [0.2040, 0.2019, 0.2014, 0.1991, 0.1935]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([4, 5])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]         100,000\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "           Dropout-3                  [-1, 100]               0\n",
      "            Linear-4                   [-1, 10]           1,000\n",
      "              ReLU-5                   [-1, 10]               0\n",
      "           Dropout-6                   [-1, 10]               0\n",
      "            Linear-7                    [-1, 5]              50\n",
      "           Softmax-8                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 101,050\n",
      "Trainable params: 101,050\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 0.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(1000, 100, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc_2 = nn.Linear(100, 10, bias=False)\n",
    "        self.fc_3 = nn.Linear(10, 5, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "input = torch.rand((4,1000))\n",
    "output = model(input)\n",
    "print(output)\n",
    "print(output.shape)\n",
    "summary(model, (1000,), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8afcd7d-fd7f-47f7-abbf-2f51e1f79ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1181, 0.2350, 0.1854, 0.2306, 0.2310],\n",
      "        [0.1779, 0.2197, 0.1979, 0.2095, 0.1950],\n",
      "        [0.1830, 0.2236, 0.2004, 0.2013, 0.1917],\n",
      "        [0.1817, 0.2231, 0.2012, 0.2048, 0.1892],\n",
      "        [0.1926, 0.2123, 0.2092, 0.1962, 0.1897],\n",
      "        [0.1459, 0.2286, 0.2116, 0.2164, 0.1974],\n",
      "        [0.1905, 0.2306, 0.2003, 0.1907, 0.1879],\n",
      "        [0.1972, 0.2047, 0.2035, 0.1986, 0.1960],\n",
      "        [0.1742, 0.2145, 0.1996, 0.2158, 0.1959],\n",
      "        [0.1907, 0.2201, 0.1969, 0.2007, 0.1915]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([10, 5])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]      19,660,800\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "           Dropout-3                  [-1, 100]               0\n",
      "            Linear-4                   [-1, 10]           1,000\n",
      "              ReLU-5                   [-1, 10]               0\n",
      "           Dropout-6                   [-1, 10]               0\n",
      "            Linear-7                    [-1, 5]              50\n",
      "           Softmax-8                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 19,661,850\n",
      "Trainable params: 19,661,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 75.00\n",
      "Estimated Total Size (MB): 75.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(256 * 256 * 3, 100, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc_2 = nn.Linear(100, 10, bias=False)\n",
    "        self.fc_3 = nn.Linear(10, 5, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 256 * 256 * 3)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "input = torch.rand((10,256,256,3))\n",
    "output = model(input)\n",
    "print(output)\n",
    "print(output.shape)\n",
    "summary(model, (256,256,3,), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b248a29-5c8d-4898-ba01-819ef80d99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94655cf1-f482-46da-8bc1-d86748b7b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0955, 0.0946, 0.0940,  ..., 0.0934, 0.0940, 0.0949],\n",
      "          [0.0948, 0.0935, 0.0932,  ..., 0.0928, 0.0934, 0.0948],\n",
      "          [0.0944, 0.0930, 0.0921,  ..., 0.0909, 0.0929, 0.0949],\n",
      "          ...,\n",
      "          [0.0939, 0.0927, 0.0914,  ..., 0.0901, 0.0924, 0.0952],\n",
      "          [0.0940, 0.0936, 0.0934,  ..., 0.0928, 0.0945, 0.0956],\n",
      "          [0.0945, 0.0948, 0.0947,  ..., 0.0940, 0.0950, 0.0954]],\n",
      "\n",
      "         [[0.1009, 0.1013, 0.1019,  ..., 0.1021, 0.1013, 0.1008],\n",
      "          [0.1020, 0.1030, 0.1031,  ..., 0.1038, 0.1014, 0.1002],\n",
      "          [0.1016, 0.1014, 0.1019,  ..., 0.1021, 0.1012, 0.1007],\n",
      "          ...,\n",
      "          [0.1014, 0.1006, 0.1017,  ..., 0.1027, 0.1013, 0.1008],\n",
      "          [0.1001, 0.0995, 0.0995,  ..., 0.1001, 0.1002, 0.0998],\n",
      "          [0.0990, 0.0977, 0.0981,  ..., 0.0988, 0.1000, 0.1006]],\n",
      "\n",
      "         [[0.1021, 0.1032, 0.1035,  ..., 0.1046, 0.1048, 0.1034],\n",
      "          [0.1030, 0.1040, 0.1048,  ..., 0.1061, 0.1055, 0.1040],\n",
      "          [0.1040, 0.1040, 0.1061,  ..., 0.1078, 0.1054, 0.1048],\n",
      "          ...,\n",
      "          [0.1047, 0.1045, 0.1065,  ..., 0.1075, 0.1050, 0.1044],\n",
      "          [0.1046, 0.1037, 0.1048,  ..., 0.1054, 0.1025, 0.1037],\n",
      "          [0.1037, 0.1031, 0.1035,  ..., 0.1030, 0.1020, 0.1029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0986, 0.0996, 0.0988,  ..., 0.0990, 0.0981, 0.0972],\n",
      "          [0.0986, 0.0998, 0.0978,  ..., 0.0977, 0.0970, 0.0954],\n",
      "          [0.0987, 0.0995, 0.0975,  ..., 0.0984, 0.0968, 0.0959],\n",
      "          ...,\n",
      "          [0.0987, 0.0995, 0.0970,  ..., 0.0968, 0.0965, 0.0963],\n",
      "          [0.0986, 0.0982, 0.0970,  ..., 0.0957, 0.0961, 0.0971],\n",
      "          [0.0988, 0.0981, 0.0985,  ..., 0.0986, 0.0981, 0.0988]],\n",
      "\n",
      "         [[0.1121, 0.1108, 0.1100,  ..., 0.1094, 0.1087, 0.1105],\n",
      "          [0.1113, 0.1103, 0.1092,  ..., 0.1083, 0.1084, 0.1104],\n",
      "          [0.1116, 0.1108, 0.1096,  ..., 0.1079, 0.1082, 0.1104],\n",
      "          ...,\n",
      "          [0.1117, 0.1103, 0.1090,  ..., 0.1083, 0.1085, 0.1103],\n",
      "          [0.1112, 0.1109, 0.1107,  ..., 0.1107, 0.1112, 0.1115],\n",
      "          [0.1118, 0.1116, 0.1117,  ..., 0.1115, 0.1111, 0.1115]],\n",
      "\n",
      "         [[0.1017, 0.1007, 0.1021,  ..., 0.1015, 0.1019, 0.1034],\n",
      "          [0.1015, 0.1008, 0.1030,  ..., 0.1018, 0.1025, 0.1041],\n",
      "          [0.1012, 0.1013, 0.1042,  ..., 0.1034, 0.1036, 0.1041],\n",
      "          ...,\n",
      "          [0.1013, 0.1015, 0.1041,  ..., 0.1043, 0.1048, 0.1043],\n",
      "          [0.1020, 0.1036, 0.1037,  ..., 0.1039, 0.1044, 0.1026],\n",
      "          [0.1022, 0.1033, 0.1026,  ..., 0.1026, 0.1029, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0955, 0.0946, 0.0941,  ..., 0.0934, 0.0940, 0.0949],\n",
      "          [0.0949, 0.0935, 0.0931,  ..., 0.0931, 0.0934, 0.0948],\n",
      "          [0.0943, 0.0931, 0.0923,  ..., 0.0908, 0.0928, 0.0949],\n",
      "          ...,\n",
      "          [0.0940, 0.0926, 0.0916,  ..., 0.0902, 0.0924, 0.0951],\n",
      "          [0.0940, 0.0934, 0.0934,  ..., 0.0932, 0.0943, 0.0956],\n",
      "          [0.0946, 0.0947, 0.0948,  ..., 0.0940, 0.0950, 0.0954]],\n",
      "\n",
      "         [[0.1010, 0.1014, 0.1020,  ..., 0.1022, 0.1013, 0.1008],\n",
      "          [0.1020, 0.1032, 0.1031,  ..., 0.1036, 0.1014, 0.1002],\n",
      "          [0.1016, 0.1015, 0.1023,  ..., 0.1022, 0.1011, 0.1008],\n",
      "          ...,\n",
      "          [0.1015, 0.1005, 0.1016,  ..., 0.1026, 0.1014, 0.1008],\n",
      "          [0.1001, 0.0997, 0.0995,  ..., 0.1002, 0.1000, 0.0998],\n",
      "          [0.0991, 0.0978, 0.0982,  ..., 0.0989, 0.1000, 0.1006]],\n",
      "\n",
      "         [[0.1022, 0.1032, 0.1037,  ..., 0.1045, 0.1047, 0.1034],\n",
      "          [0.1030, 0.1042, 0.1051,  ..., 0.1060, 0.1055, 0.1040],\n",
      "          [0.1039, 0.1039, 0.1059,  ..., 0.1074, 0.1053, 0.1048],\n",
      "          ...,\n",
      "          [0.1047, 0.1047, 0.1067,  ..., 0.1073, 0.1047, 0.1045],\n",
      "          [0.1045, 0.1038, 0.1047,  ..., 0.1048, 0.1027, 0.1036],\n",
      "          [0.1037, 0.1031, 0.1035,  ..., 0.1029, 0.1021, 0.1029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0986, 0.0997, 0.0990,  ..., 0.0988, 0.0982, 0.0972],\n",
      "          [0.0986, 0.0997, 0.0977,  ..., 0.0978, 0.0971, 0.0955],\n",
      "          [0.0987, 0.0997, 0.0970,  ..., 0.0985, 0.0970, 0.0960],\n",
      "          ...,\n",
      "          [0.0986, 0.0995, 0.0969,  ..., 0.0968, 0.0963, 0.0963],\n",
      "          [0.0986, 0.0982, 0.0970,  ..., 0.0960, 0.0962, 0.0970],\n",
      "          [0.0988, 0.0981, 0.0985,  ..., 0.0986, 0.0981, 0.0988]],\n",
      "\n",
      "         [[0.1121, 0.1108, 0.1100,  ..., 0.1095, 0.1088, 0.1105],\n",
      "          [0.1113, 0.1103, 0.1093,  ..., 0.1083, 0.1083, 0.1104],\n",
      "          [0.1116, 0.1108, 0.1097,  ..., 0.1078, 0.1085, 0.1104],\n",
      "          ...,\n",
      "          [0.1116, 0.1104, 0.1088,  ..., 0.1084, 0.1087, 0.1103],\n",
      "          [0.1111, 0.1108, 0.1107,  ..., 0.1109, 0.1112, 0.1115],\n",
      "          [0.1118, 0.1116, 0.1117,  ..., 0.1116, 0.1111, 0.1115]],\n",
      "\n",
      "         [[0.1016, 0.1007, 0.1020,  ..., 0.1017, 0.1020, 0.1034],\n",
      "          [0.1014, 0.1007, 0.1029,  ..., 0.1018, 0.1025, 0.1040],\n",
      "          [0.1013, 0.1011, 0.1038,  ..., 0.1034, 0.1036, 0.1040],\n",
      "          ...,\n",
      "          [0.1012, 0.1014, 0.1038,  ..., 0.1042, 0.1050, 0.1042],\n",
      "          [0.1019, 0.1036, 0.1037,  ..., 0.1038, 0.1045, 0.1026],\n",
      "          [0.1022, 0.1032, 0.1026,  ..., 0.1027, 0.1028, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0955, 0.0946, 0.0940,  ..., 0.0934, 0.0940, 0.0949],\n",
      "          [0.0948, 0.0934, 0.0933,  ..., 0.0928, 0.0933, 0.0948],\n",
      "          [0.0944, 0.0932, 0.0923,  ..., 0.0909, 0.0928, 0.0949],\n",
      "          ...,\n",
      "          [0.0940, 0.0927, 0.0916,  ..., 0.0903, 0.0923, 0.0952],\n",
      "          [0.0940, 0.0934, 0.0935,  ..., 0.0931, 0.0944, 0.0957],\n",
      "          [0.0946, 0.0948, 0.0947,  ..., 0.0940, 0.0950, 0.0954]],\n",
      "\n",
      "         [[0.1009, 0.1014, 0.1019,  ..., 0.1021, 0.1013, 0.1009],\n",
      "          [0.1020, 0.1031, 0.1032,  ..., 0.1037, 0.1014, 0.1002],\n",
      "          [0.1017, 0.1015, 0.1020,  ..., 0.1025, 0.1011, 0.1008],\n",
      "          ...,\n",
      "          [0.1014, 0.1004, 0.1016,  ..., 0.1027, 0.1014, 0.1008],\n",
      "          [0.1000, 0.0994, 0.0993,  ..., 0.1001, 0.1000, 0.0998],\n",
      "          [0.0991, 0.0977, 0.0981,  ..., 0.0989, 0.1000, 0.1006]],\n",
      "\n",
      "         [[0.1021, 0.1031, 0.1036,  ..., 0.1045, 0.1047, 0.1034],\n",
      "          [0.1030, 0.1041, 0.1050,  ..., 0.1059, 0.1055, 0.1040],\n",
      "          [0.1040, 0.1040, 0.1056,  ..., 0.1074, 0.1054, 0.1047],\n",
      "          ...,\n",
      "          [0.1047, 0.1045, 0.1065,  ..., 0.1071, 0.1049, 0.1044],\n",
      "          [0.1047, 0.1037, 0.1048,  ..., 0.1049, 0.1027, 0.1036],\n",
      "          [0.1037, 0.1031, 0.1034,  ..., 0.1030, 0.1020, 0.1029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0986, 0.0996, 0.0989,  ..., 0.0988, 0.0983, 0.0972],\n",
      "          [0.0986, 0.0999, 0.0977,  ..., 0.0978, 0.0972, 0.0955],\n",
      "          [0.0987, 0.0995, 0.0972,  ..., 0.0986, 0.0970, 0.0959],\n",
      "          ...,\n",
      "          [0.0986, 0.0997, 0.0971,  ..., 0.0968, 0.0964, 0.0963],\n",
      "          [0.0986, 0.0981, 0.0969,  ..., 0.0960, 0.0961, 0.0971],\n",
      "          [0.0988, 0.0982, 0.0985,  ..., 0.0986, 0.0982, 0.0989]],\n",
      "\n",
      "         [[0.1121, 0.1108, 0.1100,  ..., 0.1093, 0.1089, 0.1105],\n",
      "          [0.1114, 0.1103, 0.1093,  ..., 0.1083, 0.1084, 0.1104],\n",
      "          [0.1116, 0.1109, 0.1095,  ..., 0.1079, 0.1085, 0.1104],\n",
      "          ...,\n",
      "          [0.1118, 0.1105, 0.1085,  ..., 0.1080, 0.1086, 0.1103],\n",
      "          [0.1111, 0.1109, 0.1108,  ..., 0.1107, 0.1112, 0.1115],\n",
      "          [0.1118, 0.1116, 0.1117,  ..., 0.1115, 0.1111, 0.1115]],\n",
      "\n",
      "         [[0.1017, 0.1007, 0.1020,  ..., 0.1017, 0.1019, 0.1034],\n",
      "          [0.1015, 0.1007, 0.1028,  ..., 0.1020, 0.1026, 0.1039],\n",
      "          [0.1012, 0.1011, 0.1038,  ..., 0.1034, 0.1034, 0.1041],\n",
      "          ...,\n",
      "          [0.1012, 0.1014, 0.1043,  ..., 0.1043, 0.1049, 0.1043],\n",
      "          [0.1020, 0.1038, 0.1038,  ..., 0.1039, 0.1043, 0.1026],\n",
      "          [0.1022, 0.1034, 0.1027,  ..., 0.1026, 0.1029, 0.1019]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0955, 0.0946, 0.0940,  ..., 0.0934, 0.0940, 0.0949],\n",
      "          [0.0948, 0.0935, 0.0932,  ..., 0.0931, 0.0932, 0.0948],\n",
      "          [0.0944, 0.0930, 0.0923,  ..., 0.0909, 0.0928, 0.0948],\n",
      "          ...,\n",
      "          [0.0940, 0.0926, 0.0913,  ..., 0.0899, 0.0926, 0.0951],\n",
      "          [0.0941, 0.0934, 0.0935,  ..., 0.0930, 0.0944, 0.0957],\n",
      "          [0.0945, 0.0948, 0.0948,  ..., 0.0941, 0.0950, 0.0954]],\n",
      "\n",
      "         [[0.1009, 0.1014, 0.1018,  ..., 0.1021, 0.1013, 0.1009],\n",
      "          [0.1020, 0.1031, 0.1031,  ..., 0.1035, 0.1013, 0.1002],\n",
      "          [0.1017, 0.1014, 0.1022,  ..., 0.1022, 0.1011, 0.1008],\n",
      "          ...,\n",
      "          [0.1015, 0.1007, 0.1019,  ..., 0.1027, 0.1013, 0.1008],\n",
      "          [0.1001, 0.0997, 0.0992,  ..., 0.1001, 0.1001, 0.0998],\n",
      "          [0.0990, 0.0977, 0.0981,  ..., 0.0988, 0.1000, 0.1006]],\n",
      "\n",
      "         [[0.1022, 0.1032, 0.1035,  ..., 0.1046, 0.1048, 0.1034],\n",
      "          [0.1029, 0.1040, 0.1049,  ..., 0.1061, 0.1056, 0.1041],\n",
      "          [0.1040, 0.1040, 0.1056,  ..., 0.1075, 0.1054, 0.1047],\n",
      "          ...,\n",
      "          [0.1047, 0.1043, 0.1064,  ..., 0.1073, 0.1048, 0.1044],\n",
      "          [0.1046, 0.1038, 0.1049,  ..., 0.1052, 0.1026, 0.1037],\n",
      "          [0.1037, 0.1032, 0.1035,  ..., 0.1028, 0.1021, 0.1029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0986, 0.0996, 0.0989,  ..., 0.0989, 0.0982, 0.0972],\n",
      "          [0.0986, 0.0998, 0.0979,  ..., 0.0978, 0.0971, 0.0955],\n",
      "          [0.0987, 0.0995, 0.0972,  ..., 0.0988, 0.0969, 0.0960],\n",
      "          ...,\n",
      "          [0.0986, 0.0996, 0.0971,  ..., 0.0969, 0.0964, 0.0963],\n",
      "          [0.0985, 0.0983, 0.0968,  ..., 0.0961, 0.0960, 0.0971],\n",
      "          [0.0988, 0.0980, 0.0985,  ..., 0.0985, 0.0981, 0.0988]],\n",
      "\n",
      "         [[0.1121, 0.1108, 0.1100,  ..., 0.1093, 0.1089, 0.1105],\n",
      "          [0.1113, 0.1104, 0.1092,  ..., 0.1083, 0.1083, 0.1104],\n",
      "          [0.1116, 0.1109, 0.1093,  ..., 0.1078, 0.1085, 0.1104],\n",
      "          ...,\n",
      "          [0.1117, 0.1104, 0.1090,  ..., 0.1081, 0.1085, 0.1104],\n",
      "          [0.1112, 0.1108, 0.1109,  ..., 0.1105, 0.1112, 0.1115],\n",
      "          [0.1118, 0.1117, 0.1117,  ..., 0.1116, 0.1111, 0.1115]],\n",
      "\n",
      "         [[0.1016, 0.1007, 0.1021,  ..., 0.1017, 0.1020, 0.1034],\n",
      "          [0.1015, 0.1006, 0.1029,  ..., 0.1018, 0.1027, 0.1040],\n",
      "          [0.1011, 0.1014, 0.1042,  ..., 0.1034, 0.1034, 0.1040],\n",
      "          ...,\n",
      "          [0.1013, 0.1016, 0.1040,  ..., 0.1041, 0.1050, 0.1043],\n",
      "          [0.1020, 0.1036, 0.1038,  ..., 0.1037, 0.1046, 0.1026],\n",
      "          [0.1022, 0.1032, 0.1027,  ..., 0.1027, 0.1028, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0955, 0.0946, 0.0940,  ..., 0.0934, 0.0940, 0.0949],\n",
      "          [0.0949, 0.0936, 0.0932,  ..., 0.0929, 0.0933, 0.0948],\n",
      "          [0.0943, 0.0930, 0.0924,  ..., 0.0909, 0.0929, 0.0949],\n",
      "          ...,\n",
      "          [0.0939, 0.0926, 0.0913,  ..., 0.0901, 0.0926, 0.0952],\n",
      "          [0.0940, 0.0934, 0.0934,  ..., 0.0930, 0.0944, 0.0957],\n",
      "          [0.0945, 0.0947, 0.0948,  ..., 0.0940, 0.0950, 0.0954]],\n",
      "\n",
      "         [[0.1009, 0.1014, 0.1019,  ..., 0.1021, 0.1013, 0.1008],\n",
      "          [0.1019, 0.1032, 0.1032,  ..., 0.1036, 0.1013, 0.1002],\n",
      "          [0.1018, 0.1015, 0.1022,  ..., 0.1025, 0.1010, 0.1008],\n",
      "          ...,\n",
      "          [0.1014, 0.1005, 0.1015,  ..., 0.1027, 0.1013, 0.1008],\n",
      "          [0.1002, 0.0997, 0.0994,  ..., 0.1001, 0.0999, 0.0999],\n",
      "          [0.0990, 0.0977, 0.0982,  ..., 0.0989, 0.1000, 0.1006]],\n",
      "\n",
      "         [[0.1022, 0.1032, 0.1035,  ..., 0.1045, 0.1047, 0.1034],\n",
      "          [0.1030, 0.1040, 0.1049,  ..., 0.1063, 0.1056, 0.1040],\n",
      "          [0.1040, 0.1040, 0.1058,  ..., 0.1072, 0.1054, 0.1048],\n",
      "          ...,\n",
      "          [0.1046, 0.1046, 0.1062,  ..., 0.1073, 0.1046, 0.1044],\n",
      "          [0.1045, 0.1035, 0.1047,  ..., 0.1051, 0.1026, 0.1037],\n",
      "          [0.1037, 0.1031, 0.1036,  ..., 0.1028, 0.1021, 0.1029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0986, 0.0996, 0.0989,  ..., 0.0989, 0.0981, 0.0972],\n",
      "          [0.0986, 0.0998, 0.0979,  ..., 0.0978, 0.0970, 0.0954],\n",
      "          [0.0987, 0.0996, 0.0973,  ..., 0.0986, 0.0971, 0.0959],\n",
      "          ...,\n",
      "          [0.0987, 0.0994, 0.0969,  ..., 0.0969, 0.0962, 0.0963],\n",
      "          [0.0986, 0.0982, 0.0970,  ..., 0.0961, 0.0962, 0.0971],\n",
      "          [0.0988, 0.0980, 0.0983,  ..., 0.0986, 0.0981, 0.0988]],\n",
      "\n",
      "         [[0.1121, 0.1108, 0.1100,  ..., 0.1094, 0.1088, 0.1104],\n",
      "          [0.1114, 0.1102, 0.1090,  ..., 0.1081, 0.1083, 0.1104],\n",
      "          [0.1117, 0.1107, 0.1095,  ..., 0.1082, 0.1085, 0.1103],\n",
      "          ...,\n",
      "          [0.1117, 0.1103, 0.1091,  ..., 0.1080, 0.1086, 0.1103],\n",
      "          [0.1111, 0.1107, 0.1108,  ..., 0.1108, 0.1112, 0.1115],\n",
      "          [0.1118, 0.1116, 0.1117,  ..., 0.1116, 0.1112, 0.1115]],\n",
      "\n",
      "         [[0.1016, 0.1006, 0.1019,  ..., 0.1016, 0.1019, 0.1034],\n",
      "          [0.1015, 0.1006, 0.1027,  ..., 0.1017, 0.1026, 0.1039],\n",
      "          [0.1012, 0.1010, 0.1037,  ..., 0.1034, 0.1034, 0.1042],\n",
      "          ...,\n",
      "          [0.1012, 0.1016, 0.1043,  ..., 0.1041, 0.1052, 0.1044],\n",
      "          [0.1019, 0.1037, 0.1039,  ..., 0.1038, 0.1045, 0.1026],\n",
      "          [0.1022, 0.1033, 0.1027,  ..., 0.1026, 0.1028, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0955, 0.0946, 0.0940,  ..., 0.0934, 0.0940, 0.0949],\n",
      "          [0.0948, 0.0935, 0.0933,  ..., 0.0928, 0.0933, 0.0949],\n",
      "          [0.0945, 0.0932, 0.0924,  ..., 0.0910, 0.0929, 0.0950],\n",
      "          ...,\n",
      "          [0.0939, 0.0925, 0.0913,  ..., 0.0901, 0.0926, 0.0951],\n",
      "          [0.0940, 0.0935, 0.0934,  ..., 0.0931, 0.0944, 0.0956],\n",
      "          [0.0946, 0.0948, 0.0948,  ..., 0.0941, 0.0950, 0.0954]],\n",
      "\n",
      "         [[0.1009, 0.1013, 0.1019,  ..., 0.1022, 0.1014, 0.1008],\n",
      "          [0.1020, 0.1033, 0.1032,  ..., 0.1037, 0.1015, 0.1002],\n",
      "          [0.1018, 0.1016, 0.1018,  ..., 0.1024, 0.1010, 0.1007],\n",
      "          ...,\n",
      "          [0.1014, 0.1005, 0.1018,  ..., 0.1028, 0.1015, 0.1009],\n",
      "          [0.1001, 0.0995, 0.0991,  ..., 0.1001, 0.0999, 0.0998],\n",
      "          [0.0990, 0.0977, 0.0983,  ..., 0.0988, 0.1000, 0.1006]],\n",
      "\n",
      "         [[0.1021, 0.1032, 0.1035,  ..., 0.1044, 0.1047, 0.1034],\n",
      "          [0.1030, 0.1040, 0.1049,  ..., 0.1062, 0.1054, 0.1040],\n",
      "          [0.1039, 0.1040, 0.1059,  ..., 0.1073, 0.1055, 0.1049],\n",
      "          ...,\n",
      "          [0.1048, 0.1046, 0.1065,  ..., 0.1071, 0.1046, 0.1044],\n",
      "          [0.1046, 0.1037, 0.1050,  ..., 0.1050, 0.1027, 0.1037],\n",
      "          [0.1037, 0.1031, 0.1034,  ..., 0.1029, 0.1021, 0.1029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0986, 0.0996, 0.0989,  ..., 0.0990, 0.0982, 0.0972],\n",
      "          [0.0986, 0.0998, 0.0978,  ..., 0.0978, 0.0971, 0.0955],\n",
      "          [0.0987, 0.0996, 0.0976,  ..., 0.0981, 0.0970, 0.0959],\n",
      "          ...,\n",
      "          [0.0986, 0.0996, 0.0970,  ..., 0.0972, 0.0963, 0.0961],\n",
      "          [0.0986, 0.0983, 0.0970,  ..., 0.0959, 0.0961, 0.0970],\n",
      "          [0.0988, 0.0981, 0.0984,  ..., 0.0984, 0.0980, 0.0988]],\n",
      "\n",
      "         [[0.1121, 0.1108, 0.1100,  ..., 0.1094, 0.1088, 0.1105],\n",
      "          [0.1114, 0.1103, 0.1090,  ..., 0.1083, 0.1084, 0.1104],\n",
      "          [0.1116, 0.1107, 0.1095,  ..., 0.1080, 0.1083, 0.1104],\n",
      "          ...,\n",
      "          [0.1118, 0.1103, 0.1089,  ..., 0.1081, 0.1084, 0.1102],\n",
      "          [0.1112, 0.1108, 0.1109,  ..., 0.1106, 0.1111, 0.1115],\n",
      "          [0.1118, 0.1115, 0.1117,  ..., 0.1115, 0.1112, 0.1115]],\n",
      "\n",
      "         [[0.1017, 0.1007, 0.1020,  ..., 0.1018, 0.1019, 0.1034],\n",
      "          [0.1015, 0.1006, 0.1028,  ..., 0.1019, 0.1026, 0.1040],\n",
      "          [0.1011, 0.1011, 0.1037,  ..., 0.1035, 0.1034, 0.1041],\n",
      "          ...,\n",
      "          [0.1013, 0.1017, 0.1039,  ..., 0.1036, 0.1048, 0.1045],\n",
      "          [0.1019, 0.1036, 0.1038,  ..., 0.1039, 0.1045, 0.1026],\n",
      "          [0.1022, 0.1033, 0.1026,  ..., 0.1027, 0.1028, 0.1020]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([10, 10, 224, 224])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 222, 222]             896\n",
      "              ReLU-2         [-1, 32, 222, 222]               0\n",
      "            Conv2d-3         [-1, 64, 220, 220]          18,496\n",
      "              ReLU-4         [-1, 64, 220, 220]               0\n",
      "            Conv2d-5        [-1, 128, 218, 218]          73,856\n",
      "              ReLU-6        [-1, 128, 218, 218]               0\n",
      "   ConvTranspose2d-7         [-1, 64, 220, 220]          73,792\n",
      "              ReLU-8         [-1, 64, 220, 220]               0\n",
      "   ConvTranspose2d-9         [-1, 32, 222, 222]          18,464\n",
      "             ReLU-10         [-1, 32, 222, 222]               0\n",
      "  ConvTranspose2d-11         [-1, 10, 224, 224]           2,890\n",
      "          Softmax-12         [-1, 10, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 188,394\n",
      "Trainable params: 188,394\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 243.14\n",
      "Params size (MB): 0.72\n",
      "Estimated Total Size (MB): 244.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv_3 = nn.Conv2d(64, 128, 3)\n",
    "        self.deconv_1 = nn.ConvTranspose2d(128, 64, 3)\n",
    "        self.deconv_2 = nn.ConvTranspose2d(64, 32, 3)\n",
    "        self.deconv_3 = nn.ConvTranspose2d(32, 10, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.deconv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.deconv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.deconv_3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "input = torch.rand((10,3,224,224))\n",
    "output = model(input)\n",
    "print(output)\n",
    "print(output.shape)\n",
    "summary(model, (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d40d45-f62f-4040-918c-5422d8b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积+全连接网络实现图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eec715e5-e9b3-4879-84a3-f8714ed3c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 222, 222]             896\n",
      "              ReLU-2         [-1, 32, 222, 222]               0\n",
      "            Conv2d-3         [-1, 64, 220, 220]          18,496\n",
      "              ReLU-4         [-1, 64, 220, 220]               0\n",
      "            Linear-5                  [-1, 512]   1,585,971,712\n",
      "              ReLU-6                  [-1, 512]               0\n",
      "            Linear-7                   [-1, 10]           5,130\n",
      "           Softmax-8                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 1,585,996,234\n",
      "Trainable params: 1,585,996,234\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 71.34\n",
      "Params size (MB): 6050.10\n",
      "Estimated Total Size (MB): 6122.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc_1 = nn.Linear(64 * 220 * 220, 512)\n",
    "        self.fc_2 = nn.Linear(512, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1, 64 * 220 * 220)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "input = torch.rand((10,3,224,224))\n",
    "output = model(input)\n",
    "# print(output)\n",
    "print(output.shape)\n",
    "summary(model, (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeb67209-8e35-425e-8077-5b905802ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复现LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90f78888-1df6-4615-997d-bedc6ecf41be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Conv2d-5            [-1, 120, 1, 1]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "           Softmax-8                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool_1 = nn.MaxPool2d(2)\n",
    "        self.conv_2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = nn.MaxPool2d(2)\n",
    "        self.conv_3 = nn.Conv2d(16, 120, 5)\n",
    "        self.fc_1 = nn.Linear(120, 84)\n",
    "        self.fc_2 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = x.view(-1, 120 * 1 * 1)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x= self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet()\n",
    "input = torch.rand((5,3,32,32))\n",
    "output = model(input)\n",
    "# print(output)\n",
    "print(output.shape)\n",
    "summary(model, (3,32,32), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b86d0c71-a940-4333-a33f-adc689e4dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 222, 222]             896\n",
      "            Conv2d-2         [-1, 64, 220, 220]          18,496\n",
      "            Conv2d-3         [-1, 64, 220, 220]          36,928\n",
      "       BatchNorm2d-4         [-1, 64, 220, 220]             128\n",
      "              ReLU-5         [-1, 64, 220, 220]               0\n",
      "            Conv2d-6         [-1, 64, 220, 220]          36,928\n",
      "       BatchNorm2d-7         [-1, 64, 220, 220]             128\n",
      "           MyBlock-8         [-1, 64, 220, 220]               0\n",
      "            Conv2d-9         [-1, 64, 220, 220]          36,928\n",
      "      BatchNorm2d-10         [-1, 64, 220, 220]             128\n",
      "             ReLU-11         [-1, 64, 220, 220]               0\n",
      "           Conv2d-12         [-1, 64, 220, 220]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 220, 220]             128\n",
      "          MyBlock-14         [-1, 64, 220, 220]               0\n",
      "           Conv2d-15         [-1, 64, 220, 220]          36,928\n",
      "      BatchNorm2d-16         [-1, 64, 220, 220]             128\n",
      "             ReLU-17         [-1, 64, 220, 220]               0\n",
      "           Conv2d-18         [-1, 64, 220, 220]          36,928\n",
      "      BatchNorm2d-19         [-1, 64, 220, 220]             128\n",
      "          MyBlock-20         [-1, 64, 220, 220]               0\n",
      "           Linear-21                  [-1, 512]   1,585,971,712\n",
      "           Linear-22                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 1,586,218,570\n",
      "Trainable params: 1,586,218,570\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 461.06\n",
      "Params size (MB): 6050.94\n",
      "Estimated Total Size (MB): 6512.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class MyBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channel, out_channel, 3, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_2 = nn.Conv2d(out_channel, out_channel, 3, padding=1)\n",
    "        self.bn_2 = nn.BatchNorm2d(out_channel)\n",
    "    def forward(self, x):\n",
    "        x_1 = x\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        result = x + x_1\n",
    "        return result\n",
    "\n",
    "class MainNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv_2 = nn.Conv2d(32, 64, 3)\n",
    "        self.block_1 = MyBlock(64,64)\n",
    "        self.block_2 = MyBlock(64,64)\n",
    "        self.block_3 = MyBlock(64,64)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 220 * 220, 512),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = x.view(-1, 64 * 220 * 220)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MainNet()\n",
    "input = torch.rand((5,3,224,224))\n",
    "output = model(input)\n",
    "# print(output)\n",
    "print(output.shape)\n",
    "summary(model, (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24dbb4d-be8b-4b06-928a-b3a93879d715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
