

### 回归模型常见的性能指标

> 适合特征数较少或者实例数量不多的场景

#### 均方根误差RMSE

均方根误差（Root Mean Square Error，RMSE）是一种衡量预测模型或估计值与实际观测值之间差异的常见指标。它是通过计算预测值与实际值之间的差异的平方，然后取平均并开平方得到的。


#### 最小二乘法

最小二乘法（Least Squares Method）是一种常用的数学优化技术，用于拟合数据和估计参数。它的目标是通过调整参数的值，使得模型预测值与实际观测值之间的残差平方和最小化。

在最小二乘法中，我们首先定义一个模型，该模型可以通过一组参数来描述，然后使用观测到的数据来拟合这个模型。一般来说，我们希望模型的预测值与实际观测值之间的误差尽可能小。


> 适合特征数或者训练实例数量大到内存无法满足要求的场景

#### 梯度下降

梯度下降是一种非常通用的优化算法，能够为大范围的问题找到最优解。梯度下降的中心思想就是迭代地调整参数从而使成本函数最小化。
假设你迷失在山上的浓雾之中，你能感觉到的只有你脚下路面的坡度。快速到达山脚的一个策略就是沿着最陡的方向下坡。这就是梯度下降的做法：通过测量参数向量θ相关的误差函数的局部梯度，并不断沿着降低梯度的方向调整，直到梯度降为0，到达最小值！



