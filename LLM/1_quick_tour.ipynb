{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11549bc-710c-4d45-aa6b-c6da97322c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f717ed0a-e262-4fb5-b377-5af8e5f5a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the ğŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174e4f29-0073-4842-a748-37fd8d715f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, score: 0.5309\n",
      "label: NEGATIVE, score: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# æœ‰å¤šä¸ªè¾“å…¥çš„æƒ…å†µ\n",
    "\n",
    "results = classifier([\n",
    "    \"We hope you don't hate it.\",\n",
    "    \"That's disgusting.\"\n",
    "])\n",
    "\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fdca40-0037-415b-aa69-d1bb42d11806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»¥ä¸Šæ˜¯ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼Œè¿›è¡Œæ–‡æœ¬æƒ…ç»ªåˆ†æ\n",
    "# å…¶ä¸­pipelineæ˜¯å¤§æ¨¡å‹çš„å®ä¾‹åŒ–æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51200a35-a837-4022-9ace-73beebba0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ccd82cae224829a4d69de1f2ae7078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692e48177264e39b3c3da21e9534131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44bbfb25fe4414390b50382a1335a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdf18d723e5432a919e6b7a2bb1c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a513e441361f4ee6a07fdc00ab77bd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b19875aa2c6441984ec608c9f1cff50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. è‡ªåŠ¨éŸ³é¢‘è½¬æ–‡æœ¬\n",
    "# è¿™é‡Œä¼šæŒ‡å®šä¸€ä¸ªå¤§æ¨¡å‹,å¹¶è¿›è¡Œå®ä¾‹åŒ–\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "speech_recon = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d34c8f-2cc8-40b5-8048-f45e6be58510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff660a53d04f4df1a2941b93fe743892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a8a689d1bb45fba3d5e85c152c8842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484e3dfb5d08494785456bc40c8d7ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210296f1302940bf92060f7d4da5a6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# åŠ è½½éŸ³é¢‘æ•°æ®\n",
    "\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "# è¿™é‡Œéœ€è¦æ³¨æ„ï¼ŒåŠ è½½éŸ³é¢‘æ–‡ä»¶çš„é‡‡æ ·ç‡è¦å’Œæ¨¡å‹è®­ç»ƒçš„é‡‡æ ·ç‡åŒ¹é…\n",
    "# é‡é‡‡æ ·\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recon.feature_extractor.sampling_rate))\n",
    "\n",
    "# æŠ½å–å‰4ä¸ªé‡‡æ ·æ•°æ®è¿›è¡Œè¯­éŸ³è¯†åˆ«\n",
    "result = speech_recon(dataset[:4][\"audio\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4ffbf9-a51e-4f8f-b1b5-79b95c1ab129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n"
     ]
    }
   ],
   "source": [
    "print([d['text']  for d in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c616b19-244e-4742-82cb-5b2f3c3af96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.2712884843349457}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. åˆ†è¯å™¨\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2347681-09f7-42ec-93e9-8726980a807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# åˆ†è¯å™¨è´Ÿè´£å°†æ–‡æœ¬é¢„å¤„ç†ä¸ºæ•°å­—æ•°ç»„ï¼Œä½œä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚æœ‰å¤šç§è§„åˆ™æ§åˆ¶æ ‡è®°åŒ–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¦‚ä½•æ‹†åˆ†å•è¯ä»¥åŠåº”åœ¨ä»€ä¹ˆçº§åˆ«æ‹†åˆ†å•è¯ã€‚\n",
    "# æœ€é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œæ‚¨éœ€è¦å®ä¾‹åŒ–å…·æœ‰ç›¸åŒæ¨¡å‹åç§°çš„åˆ†è¯å™¨ï¼Œä»¥ç¡®ä¿æ‚¨ä½¿ç”¨ä¸æ¨¡å‹é¢„è®­ç»ƒæ—¶ç›¸åŒçš„åˆ†è¯è§„åˆ™ã€‚\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "# åŠ è½½åˆ†è¯å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "encoding = tokenizer(\"We are very happy to show you the Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ef29d2-b34c-48b1-bc3b-7168f858db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# åˆ†è¯å™¨è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ï¼š\n",
    "# input_idsï¼štokençš„æ•°å­—è¡¨ç¤ºã€‚\n",
    "# Attention_maskï¼šæŒ‡ç¤ºåº”æ³¨æ„å“ªäº›æ ‡è®°ã€‚\n",
    "\n",
    "encoding = tokenizer(\"We are very happy\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e08d4f2-9176-4a0e-885b-056cc57cb441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†è¯å™¨è¿˜å¯ä»¥æ¥å—è¾“å…¥åˆ—è¡¨ï¼Œå¹¶å¡«å……å’Œæˆªæ–­æ–‡æœ¬ä»¥è¿”å›å…·æœ‰ç»Ÿä¸€é•¿åº¦çš„æ‰¹æ¬¡ï¼š\n",
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f9b20b-ad7b-49d0-b528-24c69eef2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
      "         58263, 13299,   119,   102],\n",
      "        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n",
      "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a93c7da1-a66c-4045-9036-e4e1ff6c1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. AutoModel\n",
    "# Transformers æä¾›äº†ä¸€ç§ç®€å•ä¸”ç»Ÿä¸€çš„æ–¹å¼æ¥åŠ è½½é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥åƒåŠ è½½AutoTokenizerä¸€æ ·åŠ è½½AutoModelã€‚\n",
    "# å”¯ä¸€çš„åŒºåˆ«æ˜¯ä¸ºä»»åŠ¡é€‰æ‹©æ­£ç¡®çš„AutoModel ã€‚å¯¹äºæ–‡æœ¬ï¼ˆæˆ–åºåˆ—ï¼‰åˆ†ç±»ï¼Œæ‚¨åº”è¯¥åŠ è½½AutoModelForSequenceClassificationï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb16858a-96a2-4a3e-80a2-d1cb3200f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# ç°åœ¨å°†é¢„å¤„ç†åçš„ä¸€æ‰¹è¾“å…¥ç›´æ¥ä¼ é€’ç»™æ¨¡å‹ã€‚æ‚¨åªéœ€æ·»åŠ ä»¥ä¸‹å†…å®¹å³å¯è§£å‹å­—å…¸**\n",
    "pt_outputs = pt_model(**pt_batch)\n",
    "\n",
    "\n",
    "# æ¨¡å‹è¾“å‡ºlogitså±æ€§ä¸­çš„æœ€ç»ˆæ¿€æ´»ã€‚å°† softmax å‡½æ•°åº”ç”¨äº æ¥logitsæ£€ç´¢æ¦‚ç‡ï¼š\n",
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc84543a-3eee-4801-9128-923b053dbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ä¿å­˜æ¨¡å‹\n",
    "\n",
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c600f75c-5a3d-47b0-a4fd-7182e7c60562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ¨¡å‹\n",
    "\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b2448a9-e544-4922-85e7-e507f7d38a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46a9ad698434dba9b2a1f10de9a9b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# 6. å®šåˆ¶æ¨¡å‹æ„å»º\n",
    "# æ‚¨å¯ä»¥ä¿®æ”¹æ¨¡å‹çš„é…ç½®ç±»æ¥æ›´æ”¹æ¨¡å‹çš„æ„å»ºæ–¹å¼ã€‚é…ç½®æŒ‡å®šæ¨¡å‹çš„å±æ€§ï¼Œä¾‹å¦‚éšè—å±‚æˆ–æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚å½“æ‚¨ä»è‡ªå®šä¹‰é…ç½®ç±»åˆå§‹åŒ–æ¨¡å‹æ—¶ï¼Œæ‚¨å°†ä»å¤´å¼€å§‹ã€‚\n",
    "# æ¨¡å‹å±æ€§æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæ‚¨éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹ï¼Œç„¶åæ‰èƒ½ä½¿ç”¨å®ƒæ¥è·å¾—æœ‰æ„ä¹‰çš„ç»“æœã€‚\n",
    "\n",
    "# (1)é¦–å…ˆå¯¼å…¥AutoConfigï¼Œç„¶ååŠ è½½è¦ä¿®æ”¹çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚åœ¨AutoConfig.from_pretrained()ä¸­ï¼Œæ‚¨å¯ä»¥æŒ‡å®šè¦æ›´æ”¹çš„å±æ€§ï¼Œä¾‹å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼š\n",
    "\n",
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n",
    "\n",
    "# (2)ä½¿ç”¨AutoModel.from_config()ä»è‡ªå®šä¹‰é…ç½®åˆ›å»ºæ¨¡å‹ï¼š\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea9fd11-570c-4a9b-8924-ce28331ffd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2134' max='2134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2134/2134 37:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 65\u001b[0m\n\u001b[0;32m     61\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m---> 65\u001b[0m unmasker \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill-mask\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m     66\u001b[0m unmasker(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm a [MASK] model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:987\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# Impossible to guess what is the right tokenizer here\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    988\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpossible to guess which tokenizer to use. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         )\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# Instantiate tokenizer if needed\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokenizer, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[1;31mException\u001b[0m: Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer."
     ]
    }
   ],
   "source": [
    "# 7. Trainer - PyTorch ä¼˜åŒ–çš„è®­ç»ƒå¾ªç¯\n",
    "\n",
    "# æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æ ‡å‡†çš„torch.nn.Moduleï¼Œå› æ­¤æ‚¨å¯ä»¥åœ¨ä»»ä½•å…¸å‹çš„è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨å®ƒä»¬ã€‚è™½ç„¶æ‚¨å¯ä»¥ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯ï¼Œ\n",
    "# Transformers ä¸º PyTorch æä¾›äº†ä¸€ä¸ªTrainerç±»ï¼Œå…¶ä¸­åŒ…å«åŸºæœ¬è®­ç»ƒå¾ªç¯ï¼Œå¹¶ä¸ºåˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦ç­‰åŠŸèƒ½æ·»åŠ äº†é™„åŠ åŠŸèƒ½ã€‚\n",
    "\n",
    "# (1) åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# (2) æ›´æ”¹çš„æ¨¡å‹è¶…å‚æ•°ï¼Œä¾‹å¦‚å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°å’Œè®­ç»ƒå‘¨æœŸæ•°ã€‚å¦‚æœæ‚¨ä¸æŒ‡å®šä»»ä½•è®­ç»ƒå‚æ•°ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼ã€‚\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"quick_tour_train_folder/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")\n",
    "\n",
    "# (3) åŠ è½½é¢„å¤„ç†ç±»ï¼Œä¾‹å¦‚åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨æˆ–å¤„ç†å™¨\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# (4) åŠ è½½æ•°æ®é›†\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT\n",
    "\n",
    "# (5) æ ‡è®°æ•°æ®é›†ï¼Œç„¶åä½¿ç”¨mapå°†å…¶åº”ç”¨åˆ°æ•´ä¸ªæ•°æ®é›†ï¼Œ å³å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)\n",
    "\n",
    "# (6) ä»æ•°æ®é›†ä¸­åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹, DataCollatorWithPaddingçš„ä½œç”¨å°±æ˜¯å°†featuresç‰¹å¾æ•°æ®è½¬æ¢ä¸ºtensorç±»å‹çš„datasetã€‚\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# (7) å¼€å§‹æ¨¡å‹è®­ç»ƒ\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")  # doctest: +SKIP\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11eb12f2-bff8-499f-a3c2-7f68025b60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory_01 = \"./pt_save_pretrained_01\"\n",
    "tokenizer.save_pretrained(pt_save_directory_01)\n",
    "model.save_pretrained(pt_save_directory_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2a51cd-7848-46b6-9e9d-1a9f7a9dab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14579acd16824418a3950a645196269e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542982a44ba6458fb4962495c3fe0fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83cee22c0d9413e9c011219aba3cfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb17887f8fa34ef38b4c618e3396d351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc643fa04d314bafba532ad6575f99a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbae9249-60df-4f28-acd4-dd7c4b281dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 4.4111e-04, -2.6241e-01, -1.0192e-01,  ..., -6.2764e-02,\n",
       "           2.7584e-01,  3.7014e-01],\n",
       "         [ 7.2233e-01,  1.6449e-01,  4.0025e-01,  ...,  1.9161e-01,\n",
       "           4.0458e-01, -5.8094e-02],\n",
       "         [ 2.8198e-01, -1.7430e-01,  3.9075e-02,  ...,  2.7681e-02,\n",
       "           1.1886e-01,  9.1439e-01],\n",
       "         ...,\n",
       "         [ 6.8016e-01,  7.9712e-02,  8.3603e-01,  ..., -4.8959e-01,\n",
       "          -2.5017e-01, -2.3519e-01],\n",
       "         [ 3.8105e-02, -8.1751e-01, -3.4076e-01,  ...,  4.4815e-01,\n",
       "           9.6726e-02, -2.0311e-01],\n",
       "         [ 3.5750e-01,  1.9968e-01,  1.7437e-01,  ...,  1.5028e-01,\n",
       "          -2.3665e-01,  5.4390e-02]]], grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a5f967-887d-46b1-adfb-46a4758b0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./pt_save_pretrained_01\")\n",
    "model = DistilBertModel.from_pretrained(\"./pt_save_pretrained_01\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3770c7d3-3c4c-4d6b-ae95-0ca45dabff05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 1.3635e-01,  6.5187e-01,  2.1305e-01,  ...,  3.8233e-01,\n",
       "           5.2273e-01,  1.1455e+00],\n",
       "         [ 6.8016e-01,  1.0462e+00,  6.2537e-01,  ...,  3.7748e-01,\n",
       "           6.6270e-01,  2.6323e-01],\n",
       "         [ 1.1680e-03,  5.2970e-01,  1.6268e-01,  ...,  3.8032e-01,\n",
       "           6.2372e-01,  1.2062e+00],\n",
       "         ...,\n",
       "         [ 3.6534e-01,  2.7263e-01,  7.4363e-01,  ..., -4.2071e-01,\n",
       "           7.0869e-02,  2.4367e-01],\n",
       "         [-1.1648e-01,  2.2981e-01, -1.7811e-01,  ...,  6.2127e-01,\n",
       "           2.8514e-01,  7.1928e-01],\n",
       "         [-2.4972e-01,  7.3815e-01,  2.3068e-01,  ...,  5.7425e-02,\n",
       "           1.5427e-01,  5.3942e-01]]], grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f24f35-ba8a-449b-afb6-0822b16b5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
