{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11549bc-710c-4d45-aa6b-c6da97322c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f717ed0a-e262-4fb5-b377-5af8e5f5a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the 🤗 Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174e4f29-0073-4842-a748-37fd8d715f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, score: 0.5309\n",
      "label: NEGATIVE, score: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# 有多个输入的情况\n",
    "\n",
    "results = classifier([\n",
    "    \"We hope you don't hate it.\",\n",
    "    \"That's disgusting.\"\n",
    "])\n",
    "\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fdca40-0037-415b-aa69-d1bb42d11806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上是使用默认模型，进行文本情绪分析\n",
    "# 其中pipeline是大模型的实例化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51200a35-a837-4022-9ace-73beebba0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ccd82cae224829a4d69de1f2ae7078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692e48177264e39b3c3da21e9534131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44bbfb25fe4414390b50382a1335a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdf18d723e5432a919e6b7a2bb1c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a513e441361f4ee6a07fdc00ab77bd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b19875aa2c6441984ec608c9f1cff50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. 自动音频转文本\n",
    "# 这里会指定一个大模型,并进行实例化\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "speech_recon = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d34c8f-2cc8-40b5-8048-f45e6be58510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff660a53d04f4df1a2941b93fe743892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a8a689d1bb45fba3d5e85c152c8842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484e3dfb5d08494785456bc40c8d7ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210296f1302940bf92060f7d4da5a6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载音频数据\n",
    "\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "# 这里需要注意，加载音频文件的采样率要和模型训练的采样率匹配\n",
    "# 重采样\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recon.feature_extractor.sampling_rate))\n",
    "\n",
    "# 抽取前4个采样数据进行语音识别\n",
    "result = speech_recon(dataset[:4][\"audio\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4ffbf9-a51e-4f8f-b1b5-79b95c1ab129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n"
     ]
    }
   ],
   "source": [
    "print([d['text']  for d in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c616b19-244e-4742-82cb-5b2f3c3af96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.2712884843349457}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 分词器\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2347681-09f7-42ec-93e9-8726980a807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 分词器负责将文本预处理为数字数组，作为模型的输入。有多种规则控制标记化过程，包括如何拆分单词以及应在什么级别拆分单词。\n",
    "# 最重要的是要记住，您需要实例化具有相同模型名称的分词器，以确保您使用与模型预训练时相同的分词规则。\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "encoding = tokenizer(\"We are very happy to show you the Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ef29d2-b34c-48b1-bc3b-7168f858db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 分词器返回一个字典，其中包含：\n",
    "# input_ids：token的数字表示。\n",
    "# Attention_mask：指示应注意哪些标记。\n",
    "\n",
    "encoding = tokenizer(\"We are very happy\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e08d4f2-9176-4a0e-885b-056cc57cb441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词器还可以接受输入列表，并填充和截断文本以返回具有统一长度的批次：\n",
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f9b20b-ad7b-49d0-b528-24c69eef2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
      "         58263, 13299,   119,   102],\n",
      "        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n",
      "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a93c7da1-a66c-4045-9036-e4e1ff6c1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. AutoModel\n",
    "# Transformers 提供了一种简单且统一的方式来加载预训练实例。这意味着您可以像加载AutoTokenizer一样加载AutoModel。\n",
    "# 唯一的区别是为任务选择正确的AutoModel 。对于文本（或序列）分类，您应该加载AutoModelForSequenceClassification："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb16858a-96a2-4a3e-80a2-d1cb3200f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 现在将预处理后的一批输入直接传递给模型。您只需添加以下内容即可解压字典**\n",
    "pt_outputs = pt_model(**pt_batch)\n",
    "\n",
    "\n",
    "# 模型输出logits属性中的最终激活。将 softmax 函数应用于 来logits检索概率：\n",
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc84543a-3eee-4801-9128-923b053dbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 保存模型\n",
    "\n",
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c600f75c-5a3d-47b0-a4fd-7182e7c60562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b2448a9-e544-4922-85e7-e507f7d38a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46a9ad698434dba9b2a1f10de9a9b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# 6. 定制模型构建\n",
    "# 您可以修改模型的配置类来更改模型的构建方式。配置指定模型的属性，例如隐藏层或注意力头的数量。当您从自定义配置类初始化模型时，您将从头开始。\n",
    "# 模型属性是随机初始化的，您需要先训练模型，然后才能使用它来获得有意义的结果。\n",
    "\n",
    "# (1)首先导入AutoConfig，然后加载要修改的预训练模型。在AutoConfig.from_pretrained()中，您可以指定要更改的属性，例如注意力头的数量：\n",
    "\n",
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n",
    "\n",
    "# (2)使用AutoModel.from_config()从自定义配置创建模型：\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea9fd11-570c-4a9b-8924-ce28331ffd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2134' max='2134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2134/2134 37:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory quick_tour_train_folder/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 65\u001b[0m\n\u001b[0;32m     61\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m---> 65\u001b[0m unmasker \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill-mask\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m     66\u001b[0m unmasker(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm a [MASK] model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:987\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# Impossible to guess what is the right tokenizer here\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    988\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpossible to guess which tokenizer to use. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         )\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# Instantiate tokenizer if needed\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokenizer, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[1;31mException\u001b[0m: Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer."
     ]
    }
   ],
   "source": [
    "# 7. Trainer - PyTorch 优化的训练循环\n",
    "\n",
    "# 所有模型都是标准的torch.nn.Module，因此您可以在任何典型的训练循环中使用它们。虽然您可以编写自己的训练循环，\n",
    "# Transformers 为 PyTorch 提供了一个Trainer类，其中包含基本训练循环，并为分布式训练、混合精度等功能添加了附加功能。\n",
    "\n",
    "# (1) 加载预训练模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# (2) 更改的模型超参数，例如学习率、批量大小和训练周期数。如果您不指定任何训练参数，则使用默认值。\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"quick_tour_train_folder/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")\n",
    "\n",
    "# (3) 加载预处理类，例如分词器、图像处理器、特征提取器或处理器\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# (4) 加载数据集\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT\n",
    "\n",
    "# (5) 标记数据集，然后使用map将其应用到整个数据集， 即对数据集进行预处理\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)\n",
    "\n",
    "# (6) 从数据集中创建一批示例, DataCollatorWithPadding的作用就是将features特征数据转换为tensor类型的dataset。\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# (7) 开始模型训练\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")  # doctest: +SKIP\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11eb12f2-bff8-499f-a3c2-7f68025b60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory_01 = \"./pt_save_pretrained_01\"\n",
    "tokenizer.save_pretrained(pt_save_directory_01)\n",
    "model.save_pretrained(pt_save_directory_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2a51cd-7848-46b6-9e9d-1a9f7a9dab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14579acd16824418a3950a645196269e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542982a44ba6458fb4962495c3fe0fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83cee22c0d9413e9c011219aba3cfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb17887f8fa34ef38b4c618e3396d351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc643fa04d314bafba532ad6575f99a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbae9249-60df-4f28-acd4-dd7c4b281dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 4.4111e-04, -2.6241e-01, -1.0192e-01,  ..., -6.2764e-02,\n",
       "           2.7584e-01,  3.7014e-01],\n",
       "         [ 7.2233e-01,  1.6449e-01,  4.0025e-01,  ...,  1.9161e-01,\n",
       "           4.0458e-01, -5.8094e-02],\n",
       "         [ 2.8198e-01, -1.7430e-01,  3.9075e-02,  ...,  2.7681e-02,\n",
       "           1.1886e-01,  9.1439e-01],\n",
       "         ...,\n",
       "         [ 6.8016e-01,  7.9712e-02,  8.3603e-01,  ..., -4.8959e-01,\n",
       "          -2.5017e-01, -2.3519e-01],\n",
       "         [ 3.8105e-02, -8.1751e-01, -3.4076e-01,  ...,  4.4815e-01,\n",
       "           9.6726e-02, -2.0311e-01],\n",
       "         [ 3.5750e-01,  1.9968e-01,  1.7437e-01,  ...,  1.5028e-01,\n",
       "          -2.3665e-01,  5.4390e-02]]], grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a5f967-887d-46b1-adfb-46a4758b0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./pt_save_pretrained_01\")\n",
    "model = DistilBertModel.from_pretrained(\"./pt_save_pretrained_01\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3770c7d3-3c4c-4d6b-ae95-0ca45dabff05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 1.3635e-01,  6.5187e-01,  2.1305e-01,  ...,  3.8233e-01,\n",
       "           5.2273e-01,  1.1455e+00],\n",
       "         [ 6.8016e-01,  1.0462e+00,  6.2537e-01,  ...,  3.7748e-01,\n",
       "           6.6270e-01,  2.6323e-01],\n",
       "         [ 1.1680e-03,  5.2970e-01,  1.6268e-01,  ...,  3.8032e-01,\n",
       "           6.2372e-01,  1.2062e+00],\n",
       "         ...,\n",
       "         [ 3.6534e-01,  2.7263e-01,  7.4363e-01,  ..., -4.2071e-01,\n",
       "           7.0869e-02,  2.4367e-01],\n",
       "         [-1.1648e-01,  2.2981e-01, -1.7811e-01,  ...,  6.2127e-01,\n",
       "           2.8514e-01,  7.1928e-01],\n",
       "         [-2.4972e-01,  7.3815e-01,  2.3068e-01,  ...,  5.7425e-02,\n",
       "           1.5427e-01,  5.3942e-01]]], grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f24f35-ba8a-449b-afb6-0822b16b5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
