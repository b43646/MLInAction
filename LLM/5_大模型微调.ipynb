{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29db1291-4270-4855-8be7-e4ef450d980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微调预训练模型\n",
    "\n",
    "# 使用预训练模型有显着的好处。它可以降低计算成本和碳足迹，并允许您使用最先进的模型，而无需从头开始训练。 \n",
    "# Transformers 提供了针对各种任务的数千个预训练模型的访问权限。当您使用预训练模型时，您可以在特定于您的任务的数据集上对其进行训练。\n",
    "# 这被称为微调，是一种非常强大的训练技术。在本教程中，您将使用您选择的深度学习框架微调预训练模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1c5c93-8271-45d5-a1ba-7dc79661997f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 准备数据集\n",
    "\n",
    "# 在微调预训练模型之前，请下载数据集并准备进行训练。之前的教程向您展示了如何处理训练数据，现在您有机会测试这些技能！\n",
    "# 首先加载Yelp 评论数据集\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6ae4ca-4da7-4fd3-bf16-e9e7c1ffc220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要一个分词器来处理文本，并包含填充和截断策略来处理任何可变序列长度。要一步处理数据集，请使用 🤗 Datasetsmap方法对整个数据集应用预处理函数\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8fc1698-ecb2-4317-8382-1a9ed9f98e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建完整数据集的较小子集进行微调以减少所需的时间\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4b4c0b-a8db-4b55-8e7a-441d19cdf203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 2. 训练\n",
    "## 使用 PyTorch Trainer 进行训练\n",
    "## Transformers 提供了针对训练 🤗 Transformers 模型进行优化的Trainer类，让您可以更轻松地开始训练，而无需手动编写自己的训练循环。 \n",
    "## Trainer API 支持多种训练选项和功能，例如日志记录、梯度累积和混合精度。\n",
    "\n",
    "## 首先加载模型并指定预期标签的数量。从 Yelp Review数据集卡中，知道有五个标签：\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a812a49-6628-457f-8a67-88c8a0c8aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数\n",
    "\n",
    "# 创建一个TrainingArguments类，其中包含可以调整的所有超参数以及用于激活不同训练选项的标志。\n",
    "# 指定保存训练检查点的位置：\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e5f6cd-9b06-4ff2-bd22-33765c390fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价\n",
    "\n",
    "## Trainer在训练期间不会自动评估模型性能。需要向Trainer传递一个函数来计算和报告指标。 \n",
    "## Evaluate库提供了一个简单的accuracy函数，可以使用evaluate.load函数加载：\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8e2c71-e788-48cf-a666-c141f8dc44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric.compute()方法计算预测精度，在传递预测值到compute()之前，需要将logits转换为预测值(所有Transformers模型否返回logits)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b8c71cc-574e-4a9a-8061-83b9b6041aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想在微调期间监控评估指标，请在训练参数evaluation_strategy中指定参数以在每个周期结束时报告评估指标：\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e142690-e253-432d-9a0f-706e2adaf468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/transformers/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 使用模型、训练参数、训练和测试数据集以及评估函数创建一个Trainer对象：\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f07ec787-2e1b-4a8d-a100-f109f763645d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 37:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.148064</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.050453</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.080397</td>\n",
       "      <td>0.566000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=1.0791414388020832, metrics={'train_runtime': 2266.7285, 'train_samples_per_second': 1.323, 'train_steps_per_second': 0.165, 'total_flos': 789354427392000.0, 'train_loss': 1.0791414388020832, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 然后通过调用train()微调模型\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a30b4a3-73ba-4022-b3ad-f4d86cf17f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9d966618204094a5d5cf6ed22ece08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7144e23351484c088a7671d35258cdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d145ebe02f18479989888d9b969e1be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/b43646/test_trainer/commit/53ff4f8e504f7ed72cd2c05db56eecadacf74434', commit_message='End of training', commit_description='', oid='53ff4f8e504f7ed72cd2c05db56eecadacf74434', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
