{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a7b0b9dc-d7ca-4170-a94d-7143ca1e88c1",
   "metadata": {},
   "source": [
    "LangChain是一个用于开发由语言模型支持的应用程序的框架。它使应用程序能够：\r\n",
    "\n",
    "-\r\n",
    "具有上下文感知能力：将语言模型连接到上下文源（提示说明、一些镜头示例、响应的内) - ）\r\n",
    "Reason：依靠语言模型进行推理（关于如何根据提供的上下文回答、采取什操作\n",
    "\n",
    "等）\r\n",
    "该框架由几分组-\n",
    "成。\r\n",
    "\r\n",
    "LangChain 库：Python 和 JavaScript 库。包含无数组件的接口和集成、将这些组件组合成链和代理的基本运行时，以及链和代理的- 现成实现。\r\n",
    "LangChain 模板：一系列易于部署的参考架构，适用- 于各种任务。\r\n",
    "LangServe：用于将 LangChain 链部署为 REST - API 的库。\r\n",
    "LangSmith：一个开发者平台，可让您调试、测试、评估和监控基于任何 LLM 框架构建的链，并与 LangChain 无缝集成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7e393-2a82-4cc7-83c3-8b53c9e3ad18",
   "metadata": {},
   "source": [
    "### 1. LLM 链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23554e2e-c4f3-4047-8ded-278bc3066eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b152f2f8-345e-461b-a864-c2e3b8d38a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLangsmith is a programming language that can be used for testing purposes. Here are some ways in which Langsmith can help with testing:\\n\\n1. **Automated Testing**: Langsmith provides a built-in support for automated testing through its `test` module. You can write test cases in Langsmith and run them automatically to ensure that your code works as expected.\\n2. **Mocking**: Langsmith's mocking system allows you to easily create mock implementations of external dependencies, making it easier to isolate the parts of your code that are being tested. This can help you write more targeted tests and reduce the risk of introducing bugs during testing.\\n3. **Property-based Testing**: Langsmith's property-based testing support allows you to define tests based on mathematical properties of the input data, rather than just checking individual test cases. This can help you cover a wider range of inputs and scenarios, and identify potential issues earlier in the development process.\\n4. **Test-Driven Development**: Langsmith's support for test-driven development (TDD) allows you to write tests before implementing the code, ensuring that your code is designed around the tests from the start. This can help you catch bugs and design issues early on, and ensure that your code meets its functional requirements.\\n5. **Code Coverage Analysis**: Langsmith provides built-in support for code coverage analysis, which allows you to measure the amount of code that is covered by your tests. This can help you identify areas of your code that are not being tested enough, and make improvements to increase code coverage.\\n6. **Testing Frameworks**: Langsmith supports a variety of testing frameworks, including unittest, pytest, and doctest. This allows you to use the testing framework that best suits your needs, and leverage its features for writing and running tests.\\n7. **Integration Testing**: Langsmith's support for integration testing allows you to write tests that verify the interaction between different parts of your code. This can help you identify potential issues with how your code is integrating, and ensure that it functions as expected in a real-world environment.\\n8. **Performance Testing**: Langsmith provides built-in support for performance testing through its `timeit` module. You can use this module to measure the execution time of your code, and identify potential bottlenecks or areas for optimization.\\n9. **Security Testing**: Langsmith's security features allow you to write secure code by design, reducing the risk of security vulnerabilities in your application. This includes support for secure coding practices, such as input validation and error handling.\\n10. **Debugging**: Langsmith provides a built-in debugger that allows you to step through your code line by line, identify potential issues, and fix them quickly and efficiently. This can save you time and effort when debugging your code, and help ensure that it functions as expected in the end.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a033d8c8-a6f6-4237-a342-85e29a0ce37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAh, an excellent question! As a world-class technical documentation writer, I must say that Langsmith is an invaluable tool for any testing process. Here are some ways Langsmith can assist in testing:\\n\\n1. **Automated Content Generation**: With Langsmith's AI-powered content generation capabilities, you can automate the creation of test cases, test scripts, and other documentation. This saves time and effort, allowing your team to focus on more critical tasks.\\n2. **Consistency Checking**: Langsmith can help ensure consistency in your testing process by identifying and flagging any inconsistencies in your documentation. This helps maintain a uniform standard across all tests, which is crucial for accurate and reliable test results.\\n3. **Error Detection**: Langsmith's advanced AI algorithms can detect errors and discrepancies in your technical documents that might otherwise go unnoticed. This can include things like incorrect syntax, formatting issues, or even logical inconsistencies in the content.\\n4. **Test Data Generation**: Langsmith can generate test data automatically, based on the information provided in your technical documentation. This helps create a more comprehensive and diverse testing scope, ensuring that all possible scenarios are covered.\\n5. **Test Case Prioritization**: With Langsmith's ability to analyze and understand the content of your technical documents, it can help prioritize test cases based on their importance and relevance. This ensures that critical tests are executed first, reducing testing time and effort.\\n6. **Integration Testing**: Langsmith can assist in integration testing by automatically generating test cases that cover the interactions between different components or systems. This helps ensure that everything is working as expected and that there are no surprises during integration.\\n7. **Regression Testing**: Langsmith can help with regression testing by identifying areas of code that have changed since the last release, and automatically generating test cases to cover those changes. This saves time and effort compared to manually testing every possible scenario.\\n8. **Performance Tuning**: By analyzing your technical documentation, Langsmith can identify areas where performance tuning may be necessary. It can then generate test cases to optimize those areas, resulting in faster execution times and improved overall system performance.\\n9. **Accessibility Testing**: With Langsmith's ability to understand the content of your technical documents, it can help ensure that your software is accessible to all users, including those with disabilities. It can automatically generate test cases to cover accessibility requirements, such as color contrast, font size, and keyboard navigation.\\n10. **Documentation Optimization**: Finally, Langsmith can assist in optimizing your technical documentation by identifying areas where content is redundant or outdated. It can then suggest updates and improvements to ensure that your documentation is accurate, up-to-date, and easy to understand.\\n\\nIn summary, Langsmith can greatly enhance the testing process by automating various tasks, improving consistency, detecting errors, generating test data, prioritizing test cases, and optimizing technical documentation. By leveraging its AI capabilities, Langsmith can help ensure that your software is reliable, efficient, and accessible to all users.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用提示模板来指导大模型的响应，提示模板用于将原始用户输入转换为更好的 LLM 输入\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 将它们组合成一个简单的LLM链\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# 现在，我们调用它并提出同样的问题，对于技术作家来说，它应该以更合适的语气做出响应！\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5bb9e6-3a0b-4dc3-9281-714808096c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs a world-class technical documentation writer, I can provide valuable insights and tools to assist with testing. Here are some ways Langsmith can help:\\n\\n1. Content Creation: Langsmith can create comprehensive and accurate content for your product or service, including user manuals, technical guides, and troubleshooting resources. This content can be used to train testers on how to use the product effectively, ensuring that they are able to test it thoroughly and identify any issues.\\n2. Style Guides: Langsmith can help create style guides for your product or service, which can be used to ensure consistency in testing across different teams and locations. A well-defined style guide can also help testers identify and report on issues more efficiently.\\n3. Test Planning: Langsmith can assist with test planning by developing test plans and scenarios that cover all aspects of the product or service. This can help ensure that tests are thorough, well-organized, and effective in identifying issues.\\n4. Defect Reporting: Langsmith can provide tools and templates for defect reporting, which can help streamline the testing process and ensure that issues are reported consistently and accurately. This can also help testers identify and prioritize issues more efficiently.\\n5. Knowledge Management: Langsmith can assist with knowledge management by developing and maintaining a centralized repository of information on the product or service. This can help ensure that testers have access to the most up-to-date information and resources, which can improve the testing process overall.\\n6. Training: Langsmith can provide training services to help testers become proficient in using the product or service effectively. This can include hands-on training, workshops, and other forms of instruction.\\n7. Collaboration: Langsmith can facilitate collaboration between testers and developers by providing tools and resources that promote effective communication and coordination. This can help ensure that issues are identified and resolved more efficiently.\\n8. Automation: Langsmith can assist with automating testing processes, which can help reduce the time and effort required to test the product or service. This can also help identify issues more quickly and accurately.\\n9. Performance Optimization: Langsmith can provide tools and resources for performance optimization, which can help ensure that the product or service performs optimally under different conditions. This can include testing for scalability, reliability, and other performance metrics.\\n10. Continuous Improvement: Langsmith can assist with continuous improvement by providing tools and resources for monitoring and analyzing testing results. This can help identify areas for improvement and ensure that the product or service is continuously improved over time.\\n\\nIn summary, Langsmith can provide a wide range of services to assist with testing, including content creation, style guides, test planning, defect reporting, knowledge management, training, collaboration, automation, performance optimization, and continuous improvement. By leveraging these services, you can ensure that your product or service is thoroughly tested and optimally performing for your customers.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat模型的输出是一条小溪，然后使用字符串可能更方便些。这里添加简单的输出解析器将chat信息转换成字符串\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 将解析器添加之前的链上\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 再次调用\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26420afa-2f5d-4aac-b722-690025096b7f",
   "metadata": {},
   "source": [
    "### 2. 检索链 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d302d7d4-7bbe-43ad-bf7b-b1b399593357",
   "metadata": {},
   "source": [
    "为了正确回答最初的问题（“langsmith 如何帮助测试？”），我们需要向法学硕士提供额外的背景信息。\n",
    "我们可以通过检索来做到这一点。当有太多数据无法直接传递给 LLM时，检索非常有用。\n",
    "然后，可以使用检索器仅获取最相关的部分并将其传递进去。\r\n",
    "\r\n",
    "在此过程中，我们将从检索器中查找相关文档，然后将它们传递到提示符\n",
    "中。检索器可以由任何东西，如- SL 表、互联，- 但在本例中，我们将填充向量存储并将其用作检索器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bfc0d7c-582e-40b3-b67d-b2bb21d47ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the provided context, Langsmith can help with testing by allowing users to visualize their test results.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 加载要索引的数据，使用 WebBaseLoader。该组件依赖于BeautifulSoup(pip install beautifulsoup4)\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 接下来，我们需要将其索引到向量存储中。这需要一些组件，即嵌入模型和向量存储。\n",
    "# 对于嵌入模型，我们再次运行本地模型访问的示例。\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings()\n",
    "\n",
    "# 现在，我们可以使用此嵌入模型将文档提取到向量存储中。为了简单起见，我们将使用一个简单的本地向量库FAISS(pip install faiss-cpu)\n",
    "# 接下来建立索引\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# 现在已经在矢量存储中索引了这些数据，这里创建一个链\n",
    "# 该链将接受传入的问题，查找相关的文档，然后将这些文档于原始问题一起传递给LLM并要求回答原始问题。\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# 运行链\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "208d2a09-1f7b-498d-9ace-68bbb93c2cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the provided context, LangSmith can help with testing in several ways:\n",
      "\n",
      "1. Creating test cases: LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\n",
      "2. Debugging: LangSmith provides native rendering of chat messages, functions, and retrieve documents, making it easy to identify and debug issues in the application.\n",
      "3. Comparing test runs: LangSmith's comparison view allows developers to track and diagnose regressions in test scores across multiple revisions of their application.\n",
      "4. Beta testing: LangSmith enables developers to collect more data on how their LLM applications are performing in real-world scenarios, helping them understand how the app is performing and identify areas for improvement.\n",
      "5. Annotating traces: LangSmith supports sending runs to annotation queues, allowing annotators to closely inspect interesting traces and annotate them with respect to different criteria.\n",
      "6. Adding runs to a dataset: As the application progresses through the beta testing phase, LangSmith enables users to add runs as examples to datasets, expanding their test coverage on real-world scenarios.\n",
      "7. Monitoring and A/B testing: LangSmith provides monitoring charts that allow users to track key metrics over time, and allows for tag and metadata grouping, which helps users mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart.\n"
     ]
    }
   ],
   "source": [
    "# 但是，我们希望文档首先来自刚刚设置的检索器\n",
    "# 这样，对于给定的问题，可以使用检索器动态选择最相关的文档并将其传递进去。\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "# 基于输入，先检索相关文档作为context，然后将相关内容传递给后面链处理\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# 在可以调用这个链。这将返回一个字典 - 来自LLM的响应位于answer键中\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721ff18-b41d-463c-b6d1-bb77f0b18a2b",
   "metadata": {},
   "source": [
    "### 3. 对话检索"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a6b4627-71f8-441a-b6d7-8a87180c34b8",
   "metadata": {},
   "source": [
    "到目前为止，我们创建的链只能回答单个问题。人们构建的 LLM 应用程序的主要类型之一是聊天机器人。那么我们如何将这个链条变成一个可以回答后续问题的链条呢？\n",
    "\n",
    "我们仍然可以使用该create_retrieval_chain函数，但我们需要更改两件事：\n",
    "- 检索方法现在不应仅适用于最近的输入，而应考虑整个历史记录。\n",
    "- 最终的LLM 链同样应该考虑整个历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e72d7f04-da69-49d1-bbc9-ccd42c77e1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content=\"This allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新检索\n",
    "# 为了更新检索，我们将创建一个新链。该链将接受最近的输入 ( input) 和对话历史记录 ( chat_history) 并使用 LLM 生成搜索查询\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\",\"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "# 通过传入用户提出后续问题的实例来测试这一点\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c12b1-b460-4391-8e28-ffa195bad175",
   "metadata": {},
   "source": [
    "### 4. 代理\n",
    "\n",
    "由于需要OpenAI的API-KEY，所以这里跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc4bd67-69cd-4eae-84b0-d352ab09058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "# from langchain.agents import AgentExecutor, create_react_agent\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from langchain_community.llms import Ollama\n",
    "# import os\n",
    "\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"xxxxxxx\"\n",
    "\n",
    "# llm = Ollama(model=\"llama2\")\n",
    "\n",
    "# tools = [TavilySearchResults(max_results=5)]\n",
    "\n",
    "# # Get the prompt to use - you can modify this!\n",
    "# prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "\n",
    "# # Construct the ReAct agent\n",
    "# agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# # Create an agent executor by passing in the agent and tools\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "723e6a9d-040f-4f56-a117-2ad6366bfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# tool = TavilySearchResults()\n",
    "# tool.invoke({\"query\": \"What is the weather like in Shanghai today?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2ecfeb6-80ef-425a-90ca-ab6d8f19dbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' certainly! Here is an example of how to read the contents of a local file in Python:\\n```\\n# Open the file using the open() function\\nwith open(\"file.txt\", \"r\") as f:\\n    # Read the contents of the file\\n    contents = f.read()\\n\\n# Print the contents of the file\\nprint(contents)\\n```\\nIn this example, we use the `open()` function to open a file named `\"file.txt\"` in read mode (`\"r\"`). The `with` statement ensures that the file is properly closed after use, regardless of whether an exception is thrown or not. The `read()` method of the file object returns the entire contents of the file, which we then print to the console.\\n\\nNote that you will need to replace `\"file.txt\"` with the actual name and location of the file you want to read.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"xxxxxxx\"\n",
    "\n",
    "retriever = TavilySearchAPIRetriever(k=3)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based on the context provided.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    ")\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: x[\"question\"]) | retriever)\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"帮我写个python示例代码，读取本地一个文件的内容\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6c51ff4-cc21-4334-926d-f61e55c98976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the information provided by the documents, the weather in Shanghai on March 27, 2024 is expected to be around 27.8 °C (82.1 °F) during the day and 18.9 °C (66 °F) at night.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"How is the weather in shanghai on March 27, 2024?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5117da1d-3934-40a5-b209-a45cd7d054fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, the current weather in Shanghai today is sunny with a temperature of 73°F (23°C). This information can be found on the following pages:\\n\\n* Page 1: Hour-by-Hour Forecast for Shanghai - <https://www.timeanddate.com/weather/china/shanghai/hourly>\\n* Page 2: Current weather in Shanghai and forecast for today, tomorrow, and next 14 days - <https://www.timeanddate.com/weather/china/shanghai>\\n* Page 3: Weather Today for Shanghai, Shanghai, China - <https://www.accuweather.com/en/cn/shanghai/106577/weather-today/>\\n\\nAll of these sources indicate that the weather in Shanghai today is sunny and mild, with a high temperature of 23°C (73°F) and low humidity.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"How is the weather in shanghai today?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523aa690-26b3-4755-b26f-2ba75534a982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
