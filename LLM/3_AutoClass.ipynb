{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e8b323-cb33-40ec-a242-f84aa21efd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 AutoClass 加载预训练实例\n",
    "## 由于有如此多不同的 Transformer 架构，为您的检查点创建一个架构可能具有挑战性。作为 Transformers 核心理念的一部分，使库易于、简单且灵活地使用，\n",
    "## 它会AutoClass从给定的检查点自动推断并加载正确的架构。该from_pretrained()方法可让您快速加载任何架构的预训练模型，因此您无需投入时间和资源从头开始训练模型。\n",
    "## 生成这种类型的与检查点无关的代码意味着，如果您的代码适用于一个检查点，那么它将适用于另一个检查点 - 只要它经过针对类似任务的训练 - 即使架构不同。\n",
    "\n",
    "# 请记住，架构是指模型的骨架，检查点是给定架构的权重。比如BERT是一个架构，而BERTgoogle-bert/bert-base-uncased是一个检查点。模型是一个通用术语，可以表示架构或检查点。\n",
    "\n",
    "# 在本教程中，您将学习：\n",
    "\n",
    "# 加载预训练的分词器。\n",
    "# 加载预训练的图像处理器\n",
    "# 加载预训练的特征提取器。\n",
    "# 加载预训练的处理器。\n",
    "# 加载预训练模型。\n",
    "# 加载模型作为骨干。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0328e255-8c42-4ff5-9aab-a4a9b5b55ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ae543ad76486482720c48075b3d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734abd5b1c604f5c91ee0b75594af5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c56669fc114c4e9127df6b721e3d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929b9294b7434bd5a1c59a7fc66fda2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 1. 自动分词器\n",
    "# 几乎每个 NLP 任务都以分词器开始。分词器将您的输入转换为模型可以处理的格式。\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "print(tokenizer(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6c417a-b795-491b-9a34-bc08441f1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 自动图像处理器\n",
    "# 对于视觉任务，图像处理器将图像处理成正确的输入格式。\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba56dda-35eb-49a9-84ae-198e962ab23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2907dce6000544d2bd15f99c4f8be88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--microsoft--swin-tiny-patch4-window7-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6a64abfd584a0a9f3882ce92f1c153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cd947f15254268aa5bb79a1f4d9946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinBackbone were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized: ['swin.hidden_states_norms.stage1.bias', 'swin.hidden_states_norms.stage1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 3. 自动骨干网\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoBackbone\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = AutoBackbone.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\", out_indices=(1,))\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "feature_maps = outputs.feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af631bed-fedd-4c30-8759-1e6105f62d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.0064e+00,  6.3087e-01, -1.9434e-01,  ...,  3.4310e-01,\n",
       "             2.3735e-01,  1.6851e-01],\n",
       "           [ 1.1366e+00,  6.7725e-01, -2.6274e-02,  ..., -1.1405e-01,\n",
       "             6.0058e-01,  1.7787e-01],\n",
       "           [ 1.0791e+00,  5.6264e-01,  2.5349e-01,  ...,  2.9255e-01,\n",
       "             3.0649e-01,  6.1799e-01],\n",
       "           ...,\n",
       "           [ 5.0817e-01,  3.7973e-01, -7.7769e-01,  ..., -8.8344e-02,\n",
       "             5.2979e-02, -5.7092e-01],\n",
       "           [-3.7535e-01, -1.8946e-01, -3.2584e-01,  ..., -2.9201e-01,\n",
       "            -5.8429e-02,  1.2848e-01],\n",
       "           [ 2.5337e-01, -8.9120e-02,  3.7873e-01,  ..., -7.1851e-01,\n",
       "             1.3847e-01,  5.3692e-01]],\n",
       " \n",
       "          [[ 9.5971e-01,  9.7547e-01,  1.3414e+00,  ...,  8.0082e-01,\n",
       "             8.1081e-01,  7.8101e-01],\n",
       "           [ 7.9007e-01,  1.2079e+00,  1.1176e+00,  ...,  9.6235e-01,\n",
       "             6.2085e-01,  7.4454e-01],\n",
       "           [ 5.2195e-02,  9.7713e-01,  1.0464e+00,  ...,  7.8407e-01,\n",
       "             9.2501e-01,  7.9040e-01],\n",
       "           ...,\n",
       "           [ 1.5364e+00,  1.4474e+00,  1.3669e+00,  ...,  8.9157e-01,\n",
       "             1.3441e+00,  1.5203e+00],\n",
       "           [ 1.6571e+00,  1.5495e+00,  1.5782e+00,  ...,  5.1749e-01,\n",
       "             1.3361e+00,  1.4069e+00],\n",
       "           [ 1.6271e+00,  1.6741e+00,  1.5733e+00,  ...,  6.9749e-02,\n",
       "             5.9969e-01, -6.4649e-02]],\n",
       " \n",
       "          [[-1.0611e+00, -8.8618e-01, -9.2136e-01,  ..., -1.0067e+00,\n",
       "            -1.0897e+00, -1.3464e+00],\n",
       "           [-7.3551e-01, -1.3470e+00, -6.6860e-01,  ..., -1.3656e+00,\n",
       "            -9.6558e-01, -1.0946e+00],\n",
       "           [-1.0999e+00, -1.0913e+00, -7.0618e-01,  ..., -1.2244e+00,\n",
       "            -8.4158e-01, -1.8124e-01],\n",
       "           ...,\n",
       "           [-3.6143e-01, -4.4984e-01, -4.8815e-01,  ..., -1.7085e-01,\n",
       "            -7.2806e-01, -5.4693e-01],\n",
       "           [-1.0450e+00, -2.6562e-01, -7.3188e-01,  ..., -5.7306e-02,\n",
       "            -3.2417e-01, -1.3082e+00],\n",
       "           [-1.1873e+00, -4.3371e-01, -5.4502e-02,  ...,  1.2146e-01,\n",
       "            -1.6339e-01,  6.4927e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.7181e-01, -4.1788e-01, -4.9082e-01,  ..., -6.8329e-01,\n",
       "            -7.6303e-01, -1.1190e+00],\n",
       "           [-1.1031e+00, -5.4560e-01, -2.3726e-01,  ..., -8.4765e-01,\n",
       "            -7.6631e-01, -9.2620e-01],\n",
       "           [-1.4400e+00, -1.0097e+00, -6.4823e-01,  ..., -8.2203e-01,\n",
       "            -9.7641e-01, -1.2630e+00],\n",
       "           ...,\n",
       "           [-6.2639e-01, -7.3904e-01, -6.3977e-01,  ..., -1.1516e+00,\n",
       "            -1.6422e-01,  8.9247e-02],\n",
       "           [-1.9955e-01, -4.9461e-01, -7.8596e-01,  ..., -1.6575e+00,\n",
       "            -4.2794e-01, -4.2375e-01],\n",
       "           [-5.8624e-01, -1.1882e-01, -4.6758e-01,  ..., -2.0037e+00,\n",
       "            -1.3892e+00, -9.4938e-01]],\n",
       " \n",
       "          [[ 1.4773e+00,  1.2951e+00,  1.3265e+00,  ...,  1.4276e+00,\n",
       "             1.3049e+00,  1.2771e+00],\n",
       "           [ 1.2810e+00,  1.3507e+00,  1.3210e+00,  ...,  1.4253e+00,\n",
       "             1.1915e+00,  1.1442e+00],\n",
       "           [ 1.2527e+00,  1.2587e+00,  1.2366e+00,  ...,  1.2962e+00,\n",
       "             1.3330e+00,  1.3172e+00],\n",
       "           ...,\n",
       "           [ 5.9953e-01,  8.2859e-01,  9.2873e-01,  ...,  7.0422e-01,\n",
       "             3.7539e-01,  6.5606e-01],\n",
       "           [ 6.9176e-01,  4.9668e-01,  8.5061e-01,  ...,  7.1650e-01,\n",
       "             5.0627e-01,  4.6261e-01],\n",
       "           [ 6.7759e-01,  6.5011e-01,  5.5478e-01,  ...,  6.3098e-01,\n",
       "             4.0490e-01,  5.6926e-01]],\n",
       " \n",
       "          [[-6.0317e-01, -5.0964e-01, -1.4121e-01,  ..., -1.1828e-01,\n",
       "             2.1838e-02,  1.5312e-03],\n",
       "           [-9.5323e-01, -2.1130e-01, -2.8068e-01,  ..., -3.3612e-02,\n",
       "            -4.1401e-01, -3.6642e-01],\n",
       "           [-1.6695e+00, -9.9313e-01, -9.9955e-01,  ..., -4.1771e-01,\n",
       "            -1.1368e+00, -7.1428e-01],\n",
       "           ...,\n",
       "           [-3.7443e-01, -1.0206e+00,  6.1264e-02,  ..., -2.1655e-01,\n",
       "            -1.8866e-01, -3.9790e-02],\n",
       "           [-1.7580e-01, -2.1298e-01, -8.6712e-01,  ...,  8.2015e-02,\n",
       "            -1.7756e-01, -6.6991e-01],\n",
       "           [-7.7687e-01,  3.8004e-03, -4.6250e-01,  ..., -4.4390e-01,\n",
       "            -1.3550e+00, -1.3301e+00]]]], grad_fn=<CloneBackward0>),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在上图中，要从 Swin 主干的第一阶段返回特征图，您可以设置out_indices=(1,)\n",
    "feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbaa8a5-4432-4caa-bc0e-dfc65af0ea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcc98abcd634250bcc9185ce683a2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--ehcalabres--wav2vec2-lg-xlsr-en-speech-emotion-recognition. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# 4. 自动特征提取器\n",
    "# 对于音频任务，特征提取器以正确的输入格式处理音频信号。\n",
    "\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acc1424-1325-463e-a1ee-2598298729bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8606f0851fbc4c8d8ad7b73093243658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40851\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\40851\\.cache\\huggingface\\hub\\models--microsoft--layoutlmv2-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c23b82108f4189ae4f60552fdfcef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805f227a59044d33927e6d2d9fac645b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 自动处理器\n",
    "\n",
    "# 多模式任务需要一个结合了两种类型预处理工具的处理器。例如，LayoutLMV2模型需要一个图像处理器来处理图像，需要一个分词器来处理文本；处理器将两者结合在一起。\n",
    "\n",
    "# 使用AutoProcessor.from_pretrained()加载处理器\n",
    "\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ac8721-ac59-4acd-a01c-9bd49de4eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6. AutoModel\n",
    "# 这些AutoModelFor类允许您加载给定任务的预训练模型（有关可用任务的完整列表，请参阅此处）。\n",
    "# 例如，使用AutoModelForSequenceClassification.from_pretrained()加载序列分类模型：\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# 轻松重用相同的检查点来加载不同任务的架构：\n",
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# 一般来说，我们建议使用AutoTokenizer类和AutoModelFor类来加载模型的预训练实例。这将确保您每次加载正确的架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89eec3-ea82-4658-bc70-8e2276d0a05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
